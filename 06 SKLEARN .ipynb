{
 "metadata": {
  "name": "",
  "signature": "sha256:519b6ff47ae6c7637888f11cfdbbaf19be037cb7ecaa7d48888682941ff3ba01"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Intro to Scikit Learn\n",
      "\n",
      "The `scikit-learn` package is an open-source library that provides a robust set of machine learning algorithms for Python. It is built upon the core Python scientific stack (*i.e.* NumPy, SciPy, Cython), and has a simple, consistent API, making it useful for a wide range of statistical learning applications.\n",
      "\n",
      "![scikit-learn algorithms](http://1.bp.blogspot.com/-ME24ePzpzIM/UQLWTwurfXI/AAAAAAAAANw/W3EETIroA80/s1600/drop_shadows_background.png)\n",
      "\n",
      "## What is Machine Learning?\n",
      "\n",
      "Machine Learning (ML) is about coding programs that automatically adjust their performance from exposure to information encoded in data. This learning is achieved via **tunable parameters** that are automatically adjusted according to performance criteria.\n",
      "\n",
      "Machine Learning can be considered a subfield of Artificial Intelligence (AI).\n",
      "\n",
      "There are three major classes of ML:\n",
      "\n",
      "**Supervised learning**\n",
      ": Algorithms which learn from a training set of *labeled* examples (exemplars) to generalize to the set of all possible inputs. Examples of supervised learning include regression and support vector machines.\n",
      "\n",
      "**Unsupervised learning**\n",
      ": Algorithms which learn from a training set of *unlableled* examples, using the features of the inputs to categorize inputs together according to some statistical criteria. Examples of unsupervised learning include k-means clustering and kernel density estimation.\n",
      "\n",
      "**Reinforcement learning**\n",
      ": Algorithms that learn via reinforcement from a *critic* that provides information on the quality of a solution, but not on how to improve it. Improved solutions are achieved by iteratively exploring the solution space. \n",
      "\n",
      "## Representing Data in `scikit-learn`\n",
      "\n",
      "Most machine learning algorithms implemented in scikit-learn expect data to be stored in a\n",
      "**two-dimensional array or matrix**.  The arrays can be\n",
      "either ``numpy`` arrays, or in some cases ``scipy.sparse`` matrices.\n",
      "The size of the array is expected to be `[n_samples, n_features]`\n",
      "\n",
      "- **n_samples:**   The number of samples: each sample is an item to process (e.g. classify).\n",
      "  A sample can be a document, a picture, a sound, a video, an astronomical object,\n",
      "  a row in database or CSV file,\n",
      "  or whatever you can describe with a fixed set of quantitative traits.\n",
      "- **n_features:**  The number of features or distinct traits that can be used to describe each\n",
      "  item in a quantitative manner.  Features are generally real-valued, but may be boolean or\n",
      "  discrete-valued in some cases.\n",
      "\n",
      "The number of features must be fixed in advance. However it can be very high dimensional\n",
      "(e.g. millions of features) with most of them being zeros for a given sample. This is a case\n",
      "where `scipy.sparse` matrices can be useful, in that they are\n",
      "much more memory-efficient than numpy arrays."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# SK-Learn Templating -- Linear Regression -- Predicting Salary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv(\"http://data.princeton.edu/wws509/datasets/salary.dat\", sep='\\s+')\n",
      "\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from patsy import dmatrices\n",
      "# Patsy helps us get the predictor and the features properly formatted\n",
      "# We'll just take sex, year and rank\n",
      "y, X = dmatrices('sl ~ sx + yr + rk', data=data, return_type='dataframe')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LinearRegression\n",
      "\n",
      "model = LinearRegression()\n",
      "model = model.fit(X,y)\n",
      "model.score(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "model = linear_model.Ridge(alpha = .5)\n",
      "model.fit(X,y)\n",
      "\n",
      "print model.coef_\n",
      "from sklearn import linear_model\n",
      "\n",
      "model = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])\n",
      "model.fit(X,y)\n",
      "\n",
      "print model.coef_\n",
      "print model.alpha_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# INSTANT DATA SCIENCE\n",
      "#### 5 Recipes for Data Science with SK-Learn\n",
      "Using the most powerful and popular techniques\n",
      "\n",
      "* Main Source: [Jason Brownlee's Machine Learning Mastery](http://machinelearningmastery.com/get-your-hands-dirty-with-scikit-learn-now/)\n",
      "\n",
      "* Is it okay to do without understanding?  How does this relate to the distinction between \"Data Science\" and \"Science\"?\n",
      "\n",
      "# Fisher and the Iris\n",
      "One of the datasets included with `scikit-learn` is a set of measurements for flowers, each being a member of one of three species: *Iris Setosa*, *Iris Versicolor* or *Iris Virginica*. \n",
      "\n",
      "![iris](http://w3.uniroma1.it/chemo/image/iris-flower.jpg)\n",
      "![](http://note.io/1oaMIul)\n",
      "\n",
      "In all instances below, see the documentation on sklearn and viewable in this ipython notebook for the details and nuances of the algorithm."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Take a look\n",
      "iris = datasets.load_iris()\n",
      "\n",
      "df = pd.DataFrame(iris.data)\n",
      "df.columns=(iris.feature_names)\n",
      "df['Flower Type']=pd.Series(iris.target)\n",
      "df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(iris.DESCR)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](http://upload.wikimedia.org/wikipedia/commons/thumb/4/46/R._A._Fischer.jpg/200px-R._A._Fischer.jpg)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.tools.plotting.scatter_matrix(df,alpha=.8, figsize=(15,15)) \n",
      "# Creates a scatter plot of all variables along with histograms for each variable in the diagonal"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The confusion matrix:\n",
      "We use here a confusion matrix  to evaluate the quality of the output of a classifier on the iris data set. The diagonal elements represent the number of points for which the predicted label is equal to the true label, while off-diagonal elements are those that are mislabeled by the classifier. The higher the diagonal values of the confusion matrix the better, indicating many correct predictions.\n",
      "\n",
      "![](http://note.io/1uq111I)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Logistic Regression\n",
      "\n",
      "Logistic regression fits a logistic model to data and makes predictions about the probability of an event (between 0 and 1).\n",
      "\n",
      "This recipe shows the fitting of a logistic regression model to the iris dataset. Because this is a mutli-class classification problem and logistic regression makes predictions between 0 and 1, a one-vs-all scheme is used (one model per class)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Logistic Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Logistic Regression\n",
      "from sklearn import datasets\n",
      "from sklearn import metrics\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "# load the iris datasets\n",
      "dataset = datasets.load_iris()\n",
      "# fit a logistic regression model to the data\n",
      "model = LogisticRegression()\n",
      "model.fit(dataset.data, dataset.target)\n",
      "print(model)\n",
      "# make predictions\n",
      "expected = dataset.target\n",
      "predicted = model.predict(dataset.data)\n",
      "# summarize the fit of the model\n",
      "print(metrics.classification_report(expected, predicted))\n",
      "print(metrics.confusion_matrix(expected, predicted))\n",
      "# plot confusion matrix\n",
      "cm = metrics.confusion_matrix(expected, predicted)\n",
      "\n",
      "plt.matshow(cm)\n",
      "plt.title('Confusion matrix')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "\n",
      "print \"\\nThe accuracy score is: \" + str(metrics.accuracy_score(expected,predicted))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Naive Bayes\n",
      "\n",
      "Naive Bayes uses Bayes Theorem to model the conditional relationship of each attribute to the class variable.\n",
      "\n",
      "This recipe shows the fitting of an Naive Bayes model to the iris dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gaussian Naive Bayes\n",
      "from sklearn import datasets\n",
      "from sklearn import metrics\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "# load the iris datasets\n",
      "dataset = datasets.load_iris()\n",
      "# fit a Naive Bayes model to the data\n",
      "model = GaussianNB()\n",
      "model.fit(dataset.data, dataset.target)\n",
      "print(model)\n",
      "# make predictions\n",
      "expected = dataset.target\n",
      "predicted = model.predict(dataset.data)\n",
      "# summarize the fit of the model\n",
      "print(metrics.classification_report(expected, predicted))\n",
      "print(metrics.confusion_matrix(expected, predicted))\n",
      "# plot confusion matrix\n",
      "cm = metrics.confusion_matrix(expected, predicted)\n",
      "\n",
      "plt.matshow(cm)\n",
      "plt.title('Confusion matrix')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "\n",
      "\n",
      "print \"\\nThe accuracy score is: \" + str(metrics.accuracy_score(expected,predicted))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#k-Nearest Neighbor"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The k-Nearest Neighbor (kNN) method makes predictions by locating similar cases to a given data instance (using a similarity function) and returning the average or majority of the most similar data instances. The kNN algorithm can be used for classification or regression.\n",
      "\n",
      "This recipe shows use of the kNN model to make predictions for the iris dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# k-Nearest Neighbor\n",
      "from sklearn import datasets\n",
      "from sklearn import metrics\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "# load iris the datasets\n",
      "dataset = datasets.load_iris()\n",
      "# fit a k-nearest neighbor model to the data\n",
      "model = KNeighborsClassifier()\n",
      "model.fit(dataset.data, dataset.target)\n",
      "print(model)\n",
      "# make predictions\n",
      "expected = dataset.target\n",
      "predicted = model.predict(dataset.data)\n",
      "# summarize the fit of the model\n",
      "print(metrics.classification_report(expected, predicted))\n",
      "print(metrics.confusion_matrix(expected, predicted))\n",
      "# plot confusion matrix\n",
      "cm = metrics.confusion_matrix(expected, predicted)\n",
      "\n",
      "plt.matshow(cm)\n",
      "plt.title('Confusion matrix')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "\n",
      "\n",
      "print \"\\nThe accuracy score is: \" + str(metrics.accuracy_score(expected,predicted))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Classification and Regression Trees"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Classification and Regression Trees (CART) are constructed from a dataset by making splits that best separate the data for the classes or predictions being made. The CART algorithm can be used for classification or regression.\n",
      "\n",
      "This recipe shows use of the CART model to make predictions for the iris dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Decision Tree Classifier\n",
      "from sklearn import datasets\n",
      "from sklearn import metrics\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "# load the iris datasets\n",
      "dataset = datasets.load_iris()\n",
      "# fit a CART model to the data\n",
      "model = DecisionTreeClassifier()\n",
      "model.fit(dataset.data, dataset.target)\n",
      "print(model)\n",
      "# make predictions\n",
      "expected = dataset.target\n",
      "predicted = model.predict(dataset.data)\n",
      "# summarize the fit of the model\n",
      "print(metrics.classification_report(expected, predicted))\n",
      "print(metrics.confusion_matrix(expected, predicted))\n",
      "# plot confusion matrix\n",
      "cm = metrics.confusion_matrix(expected, predicted)\n",
      "\n",
      "plt.matshow(cm)\n",
      "plt.title('Confusion matrix')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "\n",
      "\n",
      "print \"\\nThe accuracy score is: \" + str(metrics.accuracy_score(expected,predicted))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Support Vector Machines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Support Vector Machine\n",
      "from sklearn import datasets\n",
      "from sklearn import metrics\n",
      "from sklearn.svm import SVC\n",
      "# load the iris datasets\n",
      "dataset = datasets.load_iris()\n",
      "# fit a SVM model to the data\n",
      "model = SVC()\n",
      "model.fit(dataset.data, dataset.target)\n",
      "print(model)\n",
      "# make predictions\n",
      "expected = dataset.target\n",
      "predicted = model.predict(dataset.data)\n",
      "# summarize the fit of the model\n",
      "print(metrics.classification_report(expected, predicted))\n",
      "print(metrics.confusion_matrix(expected, predicted))\n",
      "# plot confusion matrix\n",
      "cm = metrics.confusion_matrix(expected, predicted)\n",
      "\n",
      "plt.matshow(cm)\n",
      "plt.title('Confusion matrix')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}